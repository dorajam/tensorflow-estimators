{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSBI56o1ll-z"
   },
   "source": [
    "# Tensorflow 101: End-to-end machine learning using Estimators\n",
    "### Supporting workshop material\n",
    "By Dora Jambor and Peng Yu\n",
    "\n",
    "\n",
    "\n",
    "## Outline\n",
    "In this notebook, we are going to walk through the end-to-end machine learning process using Tensorflow's [Estimators](https://www.tensorflow.org/guide/estimators) API. Estimators simplify machine learning programming by encapsulating the following actions:\n",
    "training, evaluation, prediction, export for serving. \n",
    "This will allow us to focus our efforts on the actual prediction task, the data and the details of our model, rather than on the implementation details of the pipeline.\n",
    "\n",
    "Our prediction task today will be to classify clothing items into 10 categories. We will go through this process by the following steps:\n",
    "1. Prepare training and test datasets\n",
    "2. Choose classifier\n",
    "3. Encode features\n",
    "4. Train, Evaluate, Predict\n",
    "5. Export saved Model\n",
    "\n",
    "This walkthrough will not go into details on model deployment. For this, please refer to the [Tensorflow Serving](https://www.tensorflow.org/serving/) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnHu6LoIpZ-T"
   },
   "source": [
    "## Prepare training and test datasets\n",
    "We will work with the new generation of MNIST:  the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist). This dataset contains 60K training and 10K images of fashion articles that are categorized into 10 labels. These labels include T-Shirt/top, trouser, pullover, dress, coat, sandal, shirt, sneaker, bag, ankle boot, each mapped to a number from 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c0TEY8ciQPO3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "ZteyeimQL4Xl",
    "outputId": "8b9f72a3-bbd4-4f3f-fade-b67e9d10925a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-c5d0270e57da>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/Dora/Dora/learnings/learnings/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/Dora/Dora/learnings/learnings/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 26421880 bytes.\n",
      "WARNING:tensorflow:From /Users/Dora/Dora/learnings/learnings/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 29515 bytes.\n",
      "WARNING:tensorflow:From /Users/Dora/Dora/learnings/learnings/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 4422102 bytes.\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 5148 bytes.\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/Dora/Dora/learnings/learnings/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "dataset = input_data.read_data_sets('data/fashion', \n",
    "                                    source_url='http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/')\n",
    "label_names = ['T-shirt/top', \n",
    "               'Trouser', \n",
    "               'Pullover', \n",
    "               'Dress', \n",
    "               'Coat', \n",
    "               'Sandal',\n",
    "               'Shirt',\n",
    "               'Sneaker',\n",
    "               'Bag',\n",
    "               'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ehGKl-acqC-c",
    "outputId": "702bf7b5-36ba-4a55-d736-ded687396138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  55000\n",
      "Number of test examples:      10000\n"
     ]
    }
   ],
   "source": [
    "print 'Number of training examples: ', dataset.train.num_examples\n",
    "print 'Number of test examples:     ', dataset.test.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCbD9KTfqXZ7"
   },
   "source": [
    "## Let's look at some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "A9x3mSb2lnQ7",
    "outputId": "dc3bf32a-4a03-4b19-9c80-54c92a90f76b"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def show_image(idx, dataset=dataset.train):\n",
    "    \"\"\"Takes training example index and plots the image.\"\"\"\n",
    "    \n",
    "    plt.imshow(dataset.images[idx].reshape(28, 28))\n",
    "    print('With label: ', label_names[dataset.labels[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "x2uN2zVjl8_Z",
    "outputId": "b13c0e0c-a6cb-4463-83d6-7dcea4f177d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('With label: ', 'Bag')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "O0ROpXoUnSVo",
    "outputId": "4b128d4e-8187-47b5-da18-209b082879f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('With label: ', 'Pullover')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "4vZs60UlnUOa",
    "outputId": "fe349624-707a-428f-b6ec-028ec24ea55f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('With label: ', 'Sneaker')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(4004)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oGhmw_s7rxFT"
   },
   "source": [
    "## Choose classifier\n",
    "In this section we will define what our *model_fn* is. This will provide us the interface to do training, evaluation, prediction and exporting. Tensorflow offers two options: **premade estimators** and **custom estimators**. The latter option allows you to define your custom model_fn that best suits your prediction task. To do this, you may find [Tensorflow's mid-level APIs](https://www.tensorflow.org/guide/custom_estimators) useful such as Layers, Datasets, and Metrics.\n",
    "\n",
    "Premade estimators give you the following default models: a **Deep Neural Network (DNN)** and a **Linear Classifier**. Each model_fn comes with their own hyperparameters. For the purpose of this walkthrough, we won't go into these, but feel free to dig deeper in your own time. Before moving on, can you answer the following questions?\n",
    "\n",
    "- How does this relate to model_fn we saw earlier?\n",
    "\n",
    "- What's the purpose of this?\n",
    "\n",
    "- What criteria would you use to choose the right model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psHs2d7kqvP0"
   },
   "outputs": [],
   "source": [
    "dnn_classifier = tf.estimator.DNNClassifier\n",
    "linear_classifier = tf.estimator.LinearClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_8D3pLgqqvR6"
   },
   "outputs": [],
   "source": [
    "classifier = linear_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XUIygakvSJ5"
   },
   "source": [
    "## Encode features\n",
    "In this step, we will first define our *feature_columns* and then we'll specify our input function that will feed these with our input data.\n",
    "\n",
    "### 1. Pick feature_columns\n",
    "Feature engineering is known to be one of the biggest and most time-consuming pain points in the modeling processing to people. The FeatureColumn API makes this process not only way easier, but also encodes the best practices to avoid unnecessary bugs during this process.\n",
    "\n",
    "The FeatureColumn API provides a simple interface to specify our feature representations. It is as simple as:\n",
    "- identify our feature types\n",
    "- find the best representation that suits the chosen model.\n",
    "\n",
    "In this case, the features are pixels. If you print an example image, you'll see we have a matrix of floats. We even know the dimension of this matrix is 28x28. This is sufficient information for us to know, we will need to choose *numeric_column* as our feature representation.\n",
    "\n",
    "[Check out their API](https://www.tensorflow.org/guide/feature_columns) to see what other preprocessors this API provides.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sRkFoPYMMm9w"
   },
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(\"pixels\", shape=[28, 28])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "75cfZ8XrwoND"
   },
   "source": [
    "###  2. Prepare input function to feed data to estimator\n",
    "This step involves setting up your input data pipeline. Based on what we saw earlier, this function is required by both the train, evaluate, predict and export_savedmodel methods. The signiture of this function is the following:\n",
    "- () -> features, labels\n",
    "\n",
    "In our example, our data is stored in numpy arrays. This makes things easy because Tensorflow already has a built-in input function for numpy types: [tf.estimator.inputs.numpy_input_fn](https://www.tensorflow.org/versions/r1.4/get_started/input_fn).\n",
    "\n",
    "In general, Tensorflow's Datasets API is there to help you to specify your custom input pipeline. But for the purpose of this walkthrough, we won't go more in depth on this topic.\n",
    "\n",
    "To see some of the **parameters** this input function takes, refer to the below definitions:\n",
    "\n",
    "-  [Batch](https://developers.google.com/machine-learning/glossary/#b)\n",
    "\n",
    "    - The set of examples used in one iteration (that is, one gradient update) of model training.\n",
    "    \n",
    "\n",
    "- [Batch size](https://developers.google.com/machine-learning/glossary/#b)\n",
    "\n",
    "    - The number of examples in a batch. For example, the batch size of SGD is 1, while the batch size of a mini-batch is usually between 10 and 1000. Batch size is usually fixed during training and inference; however, TensorFlow does permit dynamic batch sizes.\n",
    "\n",
    "\n",
    "\n",
    "- [Epochs](https://developers.google.com/machine-learning/glossary/#e)\n",
    "\n",
    "    - A full training pass over the entire data set such that each example has been seen once. Thus, an epoch represents N/batch size training iterations, where N is the total number of examples.\n",
    "\n",
    "\n",
    "\n",
    "- [Steps](https://developers.google.com/machine-learning/glossary/#s)\n",
    "\n",
    "    - A forward and backward evaluation of one batch.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MnfXV2JWr67t"
   },
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"pixels\": dataset.train.images},\n",
    "    y=dataset.train.labels.astype(tf.int32.as_numpy_dtype),\n",
    "    num_epochs=None,\n",
    "    batch_size=50,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vn9VI-97sNFx"
   },
   "source": [
    "## Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "jm09dWkxndts",
    "outputId": "f28d3278-93e0-4128-e22b-67017df6e0b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12e803ed0>, '_model_dir': './tmp/linear_fmnist_model_new', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.LinearClassifier(feature_columns=feature_columns,\n",
    "                                           n_classes=10,\n",
    "                                           model_dir=\"./tmp/linear_fmnist_model_new\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ZT-UpYccM_NE",
    "outputId": "a1682150-2003-4b29-d962-173e39b4729c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Dora/Dora/learnings/learnings/lib/python2.7/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /Users/Dora/Dora/learnings/learnings/lib/python2.7/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /Users/Dora/Dora/learnings/learnings/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./tmp/linear_fmnist_model_new/model.ckpt.\n",
      "INFO:tensorflow:loss = 115.129265, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into ./tmp/linear_fmnist_model_new/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 82.99433.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x12e839f90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=train_input_fn, steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EDJP2Bc7sjYe"
   },
   "source": [
    "## Evaluate classifier\n",
    "Now that we have a trained model, we would like to evaluate the performance of the trained model by running our classifyer on images that were not seen during training. For this, we will use the test dataset, and follow a similar setup process as for training. First, we will specify the `test_input_fn`, then we will call the `evaluate` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yhSm1Ja0lRc"
   },
   "outputs": [],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    " x={\"pixels\": dataset.test.images},\n",
    " y=dataset.test.labels.astype(tf.int32.as_numpy_dtype),\n",
    " num_epochs=1,\n",
    " shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3v_GTp8HslIf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-22-17:53:38\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/linear_fmnist_model_new/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-22-17:53:39\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.6706, average_loss = 2.0839303, global_step = 100, loss = 263.78864\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: ./tmp/linear_fmnist_model_new/model.ckpt-100\n",
      "\n",
      "Test Accuracy: 67.060000%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = classifier.evaluate(input_fn=test_input_fn)\n",
    "print(\"\\nTest Accuracy: {0:f}%\\n\".format(metrics[\"accuracy\"]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5c88Vp5ubCT"
   },
   "source": [
    "## Generate predictions\n",
    "Congratulations, you've trained a model with 78.65% accuracy! Even though we could most likely achieve higher accuracy than this, for the purpose of this walkthrough, we will move on to generating predictions.\n",
    "\n",
    "Once we evaluated our model, and have confidence that it is a model that's ready to be used to serve predictions, we can gather a few prediction instances to see what our prediction process would look like. Here we can just use a few example images from the training dataset to validate our output. In real life of course we wouldn't use training images as our prediction instances - there is no need to relabel what's already labeled. Instead, we would want to get predictions on the unlabelled (and not yet seen) images.\n",
    "\n",
    "Following the earlier signiture, we first set up a `predict_input_fn`, and then feed that into the classifier's `predict` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select random example to demonstrate prediction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('With label: ', 'Sneaker')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MP07bQmulm4"
   },
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    " x={\"pixels\": dataset.train.images[500:501]},   ## Take image with index 500\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can now see the raw predictions\n",
    "Notice the schema of the output: you can verify for yourself that the outputted `class_ids`, and `classes` contain the index of the data point that has the highest probability. These `probabilities` correspond to our model's final classification layer's outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ohpcng4pnme4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/linear_fmnist_model_new/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'class_ids': array([7]),\n",
       "  'classes': array(['7'], dtype=object),\n",
       "  'logits': array([ 6.2013183, -1.7537737,  8.533355 ,  9.157687 ,  7.5339594,\n",
       "         20.260542 ,  3.9681392, 28.720633 , 15.034301 , 13.395748 ],\n",
       "        dtype=float32),\n",
       "  'probabilities': array([1.6591810e-10, 5.8215768e-14, 1.7087705e-09, 3.1902729e-09,\n",
       "         6.2900291e-10, 2.1170778e-04, 1.7784284e-11, 9.9978703e-01,\n",
       "         1.1376512e-06, 2.2100126e-07], dtype=float32)}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = classifier.predict(predict_input_fn)\n",
    "[i for i in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With the outputted label index, we can confirm that the label corresponds to the above image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/linear_fmnist_model_new/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sneaker']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = classifier.predict(predict_input_fn)\n",
    "[label_names[i['class_ids'][0]] for i in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tYfScDIlsrhM"
   },
   "source": [
    "# Export the classifier as SavedModel object\n",
    "Once we are happy with our model's performance, it is ready to be exported to a specific location either on your local machine (for serving models locally) or to some cloud location (for cloud deployment) using the Estimators' *export_savedmodel* method. For this, please follow these steps:\n",
    "\n",
    "- Specify model path\n",
    "- Prepare `serving_input_fn` for export_savedmodel method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SftVHidtE_N"
   },
   "outputs": [],
   "source": [
    "serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "                              {\"pixels\": tf.FixedLenFeature([28, 28], tf.float32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "wkdJJZfKWOzS",
    "outputId": "50deca52-06db-4ca6-d5cf-0bc902c48765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/linear_fmnist_model_new/model.ckpt-100\n",
      "WARNING:tensorflow:From /Users/Dora/Dora/learnings/learnings/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py:1044: calling add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: my_model/temp-1542909301/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "model_path = 'my_model/'\n",
    "model_location = classifier.export_savedmodel(model_path, serving_input_fn)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment and recap\n",
    "Congratulations, your exported model is now ready for deployment. You can now create a service from your model that takes requests and returns a result. You can run such a service both locally on your machine or deploy it in the cloud.\n",
    "\n",
    "The SavedModel format works well with [Tensorflow Serving](https://www.tensorflow.org/serving/), a flexible, high-performance system for serving machine learning models in production environments.\n",
    "\n",
    "Unfortunately, this tutorial won't go into details on how to deploy your models, but if you're interested in the topic, feel free to read up on Tensorflow Serving. If you are using Kubernetes, you might also find [Kubeflow](https://www.kubeflow.org/docs/about/kubeflow/) interesting, it's an open-source project dedicated to making deployments of machine learning (ML) workflows on Kubernetes simple, portable and scalable. \n",
    "\n",
    "To recap, we discussed a simple example on building an image classifier using Estimators. Estimators provided us with a flexible API to package up the training, evaluation, prediction and exporting process such that we didn't have to worry about the nitty-gritty details of how these steps are implemented.\n",
    "\n",
    "If you're keen to try your model \"in the wild\", I definitely suggest looking into the linked documentations and do the exercise of turning your model into a real service!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tensorflow-101(public use).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
